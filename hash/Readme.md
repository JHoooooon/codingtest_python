# 해시

해시는 단반향으로 동작한다.
즉 키를 통해 값을 찾을수 있지만 값을 통해 키를 찾을수 없다

찾고자 하는 값을 찾을때의연산은 `O(1)` 이다

키 자체가 해시 함수에 의해 값이 있는 인덱스가 되므로, 값을 찾기위한 탐색 과정이 필요없다
이러한 값을 인덱스로 활용하려면 적절한 변환과정이 있어야 사용가능하다

## 나눗셈법

`h(x) = x mod m`

`x` 는 `key`, `m` 은 `소수` 이다
당연하게도 `key` 를 받아 `m` 으로 나눈 나머지를 구하는 공식이다

나눗셈법의 해시 테이블 크기는 `m` 이어야 한다
이는 `나머지` 연산시 나올수 있는 값이 `0 ~ m - 1` 까지이기 때문이다

> 나눗셈법에서 `소수`가 아닌 `합성수` 를 사용하면 어떻게 될까?
>
> `소수` 를 사용하는 이유는 충돌이 덜 일어나기 위함이다.
> `소수` 는 `1` 과 `자기자신` 만을 가진 수이므로, `약수` 가 없다
> 이는 `합성수` 보다는 충돌이 덜 일어난다
>
> 만약 `m` 이 `14` 이면, `2` 와 `7` 의 배수는 충돌이 일어난다

`f(7) = 7 mod 7` 은 `0` 이다
`f(14) = 14 mod 7` 역시 `0` 이다

하지만 이러한 `소수` 역시 충돌이 발생할수 있으므로, 이를 해결해야 한다

## 체이닝

이렇게 `충돌` 이 일어날 경우, 해결하는 방법은 버깃에 링크드 리스트로 같은 해시값을 가지는
데이터를 연결하는 것이다

`f(7) = 7 mod 7` 에서 `0` 이면, `0` 번째 인덱스에 저장될 것이다.
`f(14) = 14 mod 7` 에서도 `0` 이면, 이미 `0` 번째 인덱스에 값이 있으므로,
새로운 값을 가진 메모리주소를 `next` 에 값으로 할당하여 서로 연결한다
이는 다음처럼 이루어질 것이다

```py
# h(7)
[{value: 7, next: None}, ...]

# h(14)
[{ value: 14, next: { value: 7, next: None } }, ...]


```

이처럼 처리하는 기법은, 좋은 방법은 아니라고 한다

1. 해시 테이블 공간 활용성이 떨어진다<br/>충돌이 많이 발생하면, 링크드 리스트가 길게 늘어진다.<br/>그만큼 메모리를 잡아먹는다
2. 검색 성능이 떨어진다 <br/>링크드 리스트가 길게 늘어져 `hash` 값을 찾는다면, 선형탐색이 이루어지므로 `O(n)` 이다

## open addressing (개방 주소)

빈 버킷을 찾아 충돌값을 삽입하는 방법이다.
이는 몇가지 방법으로 나누어진다

### linear probing (선형 탐사)

이는 충돌이 발생하면 다른 빈 버킷을 찾을때까지 일정한 간격으로 이동한다
공식으로 보면 다음과 같다

`h(k, i) = (h(k) + i) mod m`

여기서 `k` 는 `key` 이고, `i` 는 `간격`, `m` 은 수용가능한 `최대 버킷`이다 이다
`i` 는 `0` 부터 시작하며, 중복이 있으면 `1` 씩 증가한다

`h(k)` 는 `해시함수` 로, 해당 값이 저장될 `index` 를 반환한다

`h(k) + 0` 에 `값` 이 있다면, `h(k) + 1` 을 하여, 그다음 `버킷` 을 찾는다

> 만약 `m - 1` 보다 값이 커지면, `0` 부터 시작하여 `빈 버킷` 을 찾는다

이러한 방법으로, `비어진 버킷` 을 찾을때까지 지속 순회한다

이 방법의 단점으로는, `해시 충돌이 발생한 값` 끼리 모이는 영역이 발생한다는 것이다  
이를 흔히 `cluster` (`군집`) 을 형성한다고 말한다

### quadratic probing (이차원 조사)

공식을 보면 다음과 같다

`h(k, i) = (h(k) + i^2) mod m`

`h(k)` 는 `해시함수`, `i` 는 증가값 (`0` 부터 시작, `1` 씩 증가), `m` 은 `최대 버킷 사이즈` 이다

살펴보면, 앞과는 다르게 `i` 값에 `2` 를 제곱한 형태를 가진다
이렇게 제곱한 `index` 값을 갖는것은 `cluster`(`군집`) 형성을 막기위해, 간격을 더 준것이다

이를 보면 다음처럼 동작한다

1. `h(k)` 를 통해 반환된 `index` 값 + 0 (=`0 ^ 2`)
2. 해당 `index` 에 값이 있다.
3. `h(k)` 를 통해 반환된 `index` 값 + 1 (=`1 ^ 2`)
4. 해당 `index` 에 값이 있다.
5. `h(k)` 를 통해 반환된 `index` 값 + 4 (=`2 ^ 2`)
6. 해당 `index` 에 값이 없으면, 할당

`1`, `3` 번을 보면, 두 값은 `h(k)` 에 의해 반환된 `index` 값과 그 다음 `index` 임을 알수 있다
`5` 번은 `h(k)` 의 `index` 값 + 앞의 두 버킷(`i` 번째) 의 제곱된 수만큼 버킷을 찾아 할당한다

이렇게 하면, `cluster` 를 해결하는듯 보인다.
하지만, 이 역시 같은 충돌을 가진 여러개의 수를 한꺼번에 넣으면 `제곱된 간격` 만큼 같은 수가
계속해서 나타난다

예를 들어, `hashing` 시 `2` 인덱스가 나오는 수들을 연속적으로 넣는다면,
`2 + 0`, `2 + 1`, `2 + 4`, `2 + 9`, `2 + 16`... 처럼 정해진 간격으로 군집형태를 이룬다

> 이러한 `cluster`(`군집`) 형태를 `2차 군집` 이라 하더라..

즉, `linear probing` 과 같은 문제가 발생한다

## Double Hashing (이중해싱)

이중 해싱은 해시함수를 `2` 개 사용한다
때에 따라 해시함수를 `N` 개로 늘리기도 한다

`2` 번째 해시함수는 `1` 번째 해시 함수로 충돌이 발생하면 해당 위치를 기준으로
어떻게 위치를 정할지 결정하는 역할을 한다

공식은 다음과 같다

`h(k, i) = (h1(k) + i * h2(k)) mod m`

위를 보면 선형 탐사와 비슷하게 더하는 방식으로 데이터 위치를 정하지만
`cluster` 를 줄이기 위해 `m` 을 제곱수로 하거나 소수로 한다

이는 주어지는 키마다 점프하는 위치를 해시 함수로 다르게 해서 `cluster` 형성을 피하기 위해서이다

다음을 보자

`h1(k)` 는 `k mod m` 한 해시 함수이다
`h2(k)` 는 `k mod p` 한 해시 함수이다
이때 `m` 과 `p` 는 서로소이며 `m` 보다 작아야 한다

그럼 `h1(k)` 에 나온 `index` 값과 `i` 번째 원소와 `h2(k)` 한 `index` 값을 곱한후 더해주면
`cluster` 형성을 피할수 있게 된다

## 곱셈법

앞의 `나눗셈법` 은 어느정도 한계가 존재한다
계산했을때 나올수 있는 값의 범위는 `0 ~ k - 1` 까지만 가능하기 때문이다

더 좋은 방법으로는 곱셈법이 있다
공식은 다음과 같다

`h(x) = (((x * A) mod 1) * m)`

`m` 은 최대 버킷수이며, `A` 는 황금비인 `1.6118033...` 이다

1. `k` 에 황금비를 곱한다
2. `1` 로 나눈 나머지값을 `m` 과 곱한다
3. 나온 값에서 정수부만 취하고, 이를 `index` 로 사용한다

> 소수부를 포함한 숫자를 `1` 로 나누면 소수부만 나온다

황금비를 사용하면 `나눗셈법` 처럼 소수가 필요 없어진다
소수가 아닌 값으로 처리가 된다는것은 테이블 크기가 커져도 추가 작업이 없다는 의미이다

## 문자열 해싱

함수의 키가 `숫자` 가 아닌 문자열일때, 처리해야 할 방법이 필요하다
이를 위해 사용하는 방법이 문자열 해싱이다

수식은 다음과 같다

`h(s) = ( s[0] + s[1] * p + s[2] * p^2 + ... ) mod m`

`m` 은 `버킷의 최대크기` 이며, `p` 는 `31`, `s` 는 `문자열` 이다

> `31` 이 `메르센소수` 라서 선택했다고 한다
>
> `메르센소수` 는 `2^N - 1` 로 표시할수 있는 숫자 중 소수인 수를 말한다
> `메르센소수` 는 해시에서 충돌을 줄이는데 효과적이라는 연구결과가 있다고 한다

이 같은경우 너무 큰값이 나올수 있으므로 `overflow` 가 발생할수 있다고 한다
이를 해결하기 위해 다음의 공식을 적용한다

`h(s) = (s[0] % m + s[1] * p % m + s[2] * p^3 % m + ...s[n - 1] * p^n-1 % m) % m`
